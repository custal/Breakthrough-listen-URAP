"""
Module for curve-fitting the continuum and bandpass shapes of GBT
spectral ata, for the purpose of subtracting from a spectrum and
identifying narrow-band spectral features for further analysis.
NOTE: This code relies on the following dependency:
https://github.com/jrmontag/STLDecompose
"""

import numpy as np
import stldecompose
import itertools
from astropy.stats.sigma_clipping import sigma_clip
from scipy.optimize import curve_fit

def get_spikes(arr, period):
    """Finds the indices of the DC spikes of a GBT spectrum based on a priori
    knowledge of the periodicity of the power spectrum, assuming spikes occur
    in the center of each coarse channel. e.g., if the period is 1024 points,
    then the half-period is 512, and spikes occur at indices i={511, 511+1024,
    511+2*(1024), ...}.

    Args:
    -----
    arr (1-D iterable): data
    period (int): number of bins in a coarse channel
            (e.g. 1024 for mid-resolution product)

    Returns:
    --------
    spikes (np.array): List of indices at which the spikes occur.
    """

    last_index = len(arr)-1
    #Spikes are assumed to start half a period from beginning
    #of data and repeat with the given periodicity.
    spikes = np.arange(0, last_index, period)
    return spikes

def remove_spikes(data, period):
    """Crudely neutralizes DC spikes in GBT spectra by setting
    the value at each spike to the value of the freq bin directly
    to the left of it.

    Args:
    -----
    data (1-D iterable): data
    period (int): number of bins in a coarse channel
            (e.g. 1024 for mid-resolution product)

    Returns:
    --------
    newdata (np.array): data with value at at each DC spike
        changed to the preceding value
    """

    newdata = [x for x in data]
    spikes = get_spikes(data, period)
    for i in np.arange(len(data)):
        if i in spikes:
            newdata[i]=newdata[i-1]
    return np.array(newdata)

def clip(x, y, sigma_lower, sigma_upper):
    """Wrapper function around astropy.stats.sigma_clipping.sigma_clip.
    Unlike sigma_clip, which returns a masked array, this function
    returns x and y arrays with the clipped indices removed, as well as
    a list of the clipped indices. See astropy sigma_clip docs for more
    info on the sigma clipping procedure.

    Args:
    -----
        x (1-D iterable): x-values
        y (1-D iterable): y-values (the values to be clipped)
        sigma_lower (positive float or `None`): number of sigma to use as
            lower bound for clipping (see astropy sigma_clip docs).
        sigma_upper (positive float or `None`): number of sigma to use as
            upper bound for clipping (see astropy sigma_clip docs)

    Returns:
    --------
        clipped_x (np.array): x-values with values at clipped indices removed
        clipped_y (np.array): y-values with values at clipped indices removed
        idx_rejected (np.array): indices of values in the original x-, y-values
            that were removed by clipping
    """

    clipped = sigma_clip(y, sigma_lower=sigma_lower, sigma_upper=sigma_upper)
    rejected = np.ma.getmask(clipped) #Boolean array
    idx_rejected = np.where(rejected)[0] #indices of clipped values
    clipped_x = np.delete(y, idx_rejected)
    clipped_y = np.delete(x, idx_rejected)
    return clipped_x, clipped_y, idx_rejected

def _smart_split(data, period=1024):
    """This is a helper function for spec_fit_STL. Its purpose is
    to attempt to split the data into chunks in order to improve
    perfomance when feeding the data to _spec_fit_STL_raw.
    If the user does not provide a chunk size, this function gets
    called. It attempts to split the data into chunks of anywhere between
    64 and 32 periods in increments of 4 periods; i.e. it will first
    try 64, then 60, then 56, and so on, stopping at the largest chunk
    size that works.

    The motivation for these numbers is that typically a spliced 1500
    MHz file will consist of 64*8 coarse channels,

    Args:
    ~~~~~

    data (1-D np.array) : data to be split
    period (int) : the number of values along `data` that
        constitutes a coarse channel. In the mid-resolution
        GBT files, this value is 1024. Note that this function
        assumes `data` starts at the beginning of a period
        and ends at the end of a period.

    Returns:
    ~~~~~~~~
    chunks (2-D np.array) : `data` reshaped into chunks. The
        0th axis is the chunk number, the 1st axis is
        the data in that chunk. e.g., if `data` has length
        524,288 and period = 1024, `data` will be split into
        8 chunks of length 65536 (=64 coarse channels * 1024
        values per coarse channel), and thus `chunks` will
        have shape (8, 65536)

    Raises:
    ~~~~~~~~
    ValueError : if, for the given period length, no number
        n in (64, 60, 56, ..., 32) results in a successful
        division of `data` into chunks of n periods
    """

    succeeded = False
    lengths = np.arange(64, 28, -4)
    for length in lengths:
        try:
            chunks = data.reshape(-1, length*period)
            succeeded = True
            break
        except:
            pass
    if succeeded is False:
        raise ValueError("Data could not be split evenly into chunks of n periods of" \
                         " size {0} for any value of n between {1} and {2}."
                         .format(period, lengths[0],lengths[-1]))
    else:
        return chunks

def split_into_chunks(data, chunk_size):
    try:
        chunks = data.reshape(-1, chunk_size)
    except:
        raise ValueError("Given chunk size ({0}) does not divide evenly into the number "\
                     "of values in the data ({1})." .format(chunk_size, len(data)))
    return chunks

def _spec_fit_STL_raw(freqs, data, period):
    """This function uses a multi-step procedure based on Seasonal-Trend
    decomposition using LOWESS (STL) to create a fit to the continuum and
    periodic components of a GBT spectrum. Narrow-band features (i.e.,
    features smaller, in frequency space, than the size of a coarse channel)
    are not fit. Hence, this enables further analysis such as thresholding of
    the residuals (data minus fit) in order to identify narrow-band features
    of interest.

    NOTE: MAKE SURE `data` IS HOMOSCEDASTIC (i.e. the periodicity has constant
    amplitude throughout the spectrum), as the fitting will fail otherwise.
    Typically this is achieved by letting `data` be the logarithm of your raw spectrum.

    Args:
    -----
    freqs (1-D iterable): frequencies
    data (1-D iterable): power values corresponding to freqs
    period (int): number of bins in a coarse channel
    Returns:
    --------
    optimized_stl (1-D np.array): an STL fit to the continuum and periodic
        components of the data. Each value in the fit array corresponds
        to the same index in the `freqs` or `data` args.
    """

    freqs = np.array(freqs)
    data = np.array(data)
    data = remove_spikes(data, period)

    #Create an initial fit to the continuum. At each point a weighted regression
    #is performed on the three coarse channels in the vicinity of the point
    #(i.e. the 1.5 coarse channels to the left and the 1.5 to the right)
    stl1 = stldecompose.decompose(data, period=period, lo_frac=3.*period/len(data),
                                   lo_delta=.05*period/len(data))
    continuum_fit = stl1.trend

    #Find outliers
    idx_rejected = clip(freqs, data - continuum_fit, sigma_lower=100, sigma_upper=.25)[2]

    #Replace outliers with continuum_fit values. The purpose of this
    #is to neutralize the impact of values high above the continuum and
    #then perform a second fit using a smaller window.
    modified_data = np.array([x for x in data])
    modified_data[idx_rejected] = continuum_fit[idx_rejected]

    #Do another STL on this, using a regression window of only the surround .75
    #coarse channels. This will do a better job of capturing the bandpass
    #structure. 0.75 was found by trial and error to yield a good compromise
    #between overfitting and accurately capturing the bandpass structure
    stl2 = stldecompose.decompose(modified_data, period=period, lo_frac=.75*period/len(data),
                                   lo_delta=.05*period/len(modified_data))

    #The seasonal component generated by the second STL fit is found to
    #sometimes have a slight vertical offeset. We remedy this by adding a
    #constant C to all values in the new fit and performing least-
    #squares optimization of C with respect to the continuum-subtracted
    #spectrum (thus the squared errors will not be affected by outliers).
    def stl_optimize(freqs, C):
        fit = np.array(stl2.trend)+np.array(stl2.seasonal)
        fit += np.array([C]*len(freqs)) #Add constant vertical shift
        return np.array(fit)

    #Start the optmization with an initial guess of C=0
    params = curve_fit(stl_optimize, freqs, modified_data, p0=0)[0]
    optimized_stl = stl_optimize(freqs, *params)
    return np.array(optimized_stl)

def spec_fit_STL(freqs, data, period, chunk_size=None, smart_split=False):
    """This is a wrapper around _spec_fit_STL_raw. For details on
    the fitting procedure, see the documentation for _spec_fit_STL_raw.

    Currently, the main added functionality of this wrapper function is
    the option to break the data up into chunks before feeding it to
    _spec_fit_STL_raw. The purpose of this is to keep the runtime of the
    fitting algorithm (which is slightly greater than O(n)) under control.
    If you only provide `freqs`, `data`, and `period`, the inputs will be
    passed straight to _spec_fit_STL_raw with no preprocessing.

    Args:
    -----
    freqs (1-D iterable): frequencies
    data (1-D iterable): power values corresponding to freqs
    period (int): number of bins in a coarse channel
    chunk_size (int) (optional) : if you want to split your data into
        chunks before fitting, this is the number of values in each chunk.
        The code will use the split_into_chunks function in this module
        to attempt to split your data into equal pieces of length
        equal to chunk_size. Make sure you have verified beforehand that
        this number will divide evenly into len(data)
    smart_split (bool) (default False) : this argument only has an effect if
        no value for chunk_size is provided. If smart_split is False, `freqs`
        and `data` will be passed to _spec_fit_STL_raw in one piece, i.e. no
        splitting of data will be attempted. If smart_split is True, _smart_split
        will be called on `freqs` and `data` to attempt to split them before
        feeding them to _spec_fit_STL_raw.
    Returns:
    --------
    fit (1-D np.array): an STL fit to the continuum and periodic
        components of the data. See _spec_fit_STL_raw documentation
        for more details.
    """

    if chunk_size is None:
        if smart_split is True:
            print("Attempting to split data into chunks...")
            freq_chunks = _smart_split(freqs, period)
            data_chunks = _smart_split(data, period)
            num_chunks = len(freq_chunks)
            chunk_fits = [_spec_fit_STL_raw(freq_chunks[i], data_chunks[i], period=period) \
                      for i in np.arange(num_chunks)]
            fit = np.array(list(itertools.chain.from_iterable(chunk_fits)))
        else:
            fit = _spec_fit_STL_raw(freqs, data, period)
    elif chunk_size is not None:
        freq_chunks = split_into_chunks(data=freqs, chunk_size=chunk_size)
        data_chunks = split_into_chunks(data=data, chunk_size=chunk_size)
        num_chunks = len(freq_chunks)

        chunk_fits = [_spec_fit_STL_raw(freq_chunks[i], data_chunks[i], period=period) \
                      for i in np.arange(num_chunks)]
        fit = np.array(list(itertools.chain.from_iterable(chunk_fits)))
    return fit
